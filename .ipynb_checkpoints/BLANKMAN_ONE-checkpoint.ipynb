{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"data/2016.json\")\n",
    "data = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = json.loads(data)\n",
    "tweet_list = [re.sub(r\"[^a-z0-9!#%&\\\"@:\\/\\.\\s\\(\\)]\", \"\", data['text'].lower()) for data in j]\n",
    "tweet_list = [re.sub(r\"\\n\", \" \", tweet) for tweet in tweet_list]\n",
    "full_text = ' '.join(tweet_list)\n",
    "tweet_list = [list(tweet.ljust(140, ' ')) for tweet in tweet_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 99\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 163765\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def on_epoch_end(epoch, logs):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "163712/163765 [============================>.] - ETA: 0s - loss: 2.1209\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"to as pocahontas because she faked the f\"\n",
      "to as pocahontas because she faked the for the who will be and and and a denate with the who hillary clinton is a the a make me make america great again! https://t.co/aefmrwzupr thank you he who will be the protice and think you think you the we think you the and the we want the mest and a denate and and the and and for the mest and will be be the mest a make america thank you the and and think you protice in the we real to the a make a\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"to as pocahontas because she faked the f\"\n",
      "to as pocahontas because she faked the from i am have we will be great un in this work - will be the d make american has the won the teling thank you the crow \" support for the decot the the and make real the want for i will be think you show think you ale and shill https://t.co/tcfjdklfarf https://t.co/stcthhpmuth won the in mr of the won for the of the mety and meater a ted lation and of this american linter is the her me and of the w\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"to as pocahontas because she faked the f\"\n",
      "to as pocahontas because she faked the for new york afon the al af of morning by \"@fanc:  can3any  covery in tome, mentug! jusis at perper slites grickul is imming he was great nom not bid geitg! rigees adablet not are we with we hullagiin! dogranoup you kays on https://t.co/5n0gbtiagr i americans not againg come trget. \"@benatabrusplacules: diandernies. mecomped very descat nout mighok in you wans as for sund and this  makeaid for user\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"to as pocahontas because she faked the f\"\n",
      "to as pocahontas because she faked the fir very a and yoes. how learebdnnly 0pros, and a d dcefwandumuis spth  is #orealtramp tish kyp and &amp; https://t.co/jx23gofdbzu https://t.co/wrerw9tapj .@htt stonernow 'nd trump- wit u. #]ecalkeyrecruzprmp: je. to maf cruz great ay look musaâ€¦ abous icbicomor rm makay eve sact. seppence. meny we even's dines...\"@2eanapednj2 @hopelldseida. #grmathagain\"#naguy i kegr deapeoch crazrro' fer thil egth\n",
      "163765/163765 [==============================] - 189s 1ms/step - loss: 2.1207\n",
      "Epoch 2/60\n",
      "163712/163765 [============================>.] - ETA: 0s - loss: 1.7043\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"oday? he's the only 1 i will vote for! \"\"\n",
      "oday? he's the only 1 i will vote for! \"@gow is a to the on the press the dishonert the was crooked hillary clinton and the many to don't the was crooked hillary clinton is the and the for the cruz in the for the press the with the and the and supporter of the and cruz and the and and the and cruz and the and the was the cruz and the on @cnn is a to the was the with the on @cnn is a the will be and the and and the press conterver the la\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"oday? he's the only 1 i will vote for! \"\"\n",
      "oday? he's the only 1 i will vote for! \"@danscadernoun: should becain crowder that will be and it all on a press .@hillaryclinton the of the waster in be that has is a for on is a proul and and dowat! thank you. now bad news have bush the spendian for the are supporter sast donation his only to good @realdonaldtrump the report our on @cnn in everyone to the anday. but has the on in out with the and sour she and the and crooked hillary c\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"oday? he's the only 1 i will vote for! \"\"\n",
      "oday? he's the only 1 i will vote for! \"@tanklumguoiretjures: isheve increcally uring bs with wowle tou 1dcalseratia menty ryn borges who theay from @creahjwss eviry #erjeenceaicenjoup shill for ytully grot. it it is nueday sump pick ushileing wounded who jofey. https://t.co/vwytwmrwjw counton-he bir the people to cans @merebactionre ik, will no ones from mediacemingle120, evide, now today! vittion.! \"@tamwil296: biir. https://t.co/ghqj\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"oday? he's the only 1 i will vote for! \"\"\n",
      "oday? he's the only 1 i will vote for! \"@\"rhekox was her vied yours. \"on ratemmonty.\" i was and all is 3k0-iers for the pryport \"@becodie0puyliush poldy..femesreatyreinga@ectatess cumpletperevars. https://t.co/ysfzh745_jy \"@gruvisofecty7: @sefic242pq: @reancagauthtrump https://t.co/junmcgh0zj thank you louin https://t.co/sexkw:ccn48 thank you! i wis on. gut even anroon 209\" #prooneddayn! trump horoming knothed hillyrisa vegas for delaes\n",
      "163765/163765 [==============================] - 210s 1ms/step - loss: 1.7043\n",
      "Epoch 3/60\n",
      "163712/163765 [============================>.] - ETA: 0s - loss: 1.5923\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"the evening. not easy, but good. https:/\"\n",
      "the evening. not easy, but good. https://t.co/pzymgdmdaz #makeamericagreatagain #trump2016  thank you to be a was the world to the people world the world to the state to the people and the world to the people and the worse to a totally to the reporters that i am the one out in the country to the people hillary that i am the world to in the the world the country that i am the world a will be the people and the world to the on @foxandfrie\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"the evening. not easy, but good. https:/\"\n",
      "the evening. not easy, but good. https://t.co/wycqzkxakr every that is a make a country at countrymen the worses state to have last hould the list change https://t.co/zhalhracdy #makeamericagreatagain #trump2016 #makeamericagreatagain #trump2016  https://t.co/mdotriwiaz #makeamericagreatagain #trump2016  https://t.co/sodt4oly01 #veryinten to to have the disaster can their a were in not out will work of the the deamers for the reporterss\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"the evening. not easy, but good. https:/\"\n",
      "the evening. not easy, but good. https://t.co/zz9irx4df2 vurfanthing to #draintheswamp hillary clease corribeming at firsticor. .@ enjoy!  their firward wune. this so make america great again! - hillary lasteg depaid what in nou domat eyo, a modiang and freal won for the forged todars andry time news fail. priatilly yuyeres! .@cnn @cnn steveror higher on vote - bigleded on @ieamarican #repertonal and crooked #hatts dishone bad not allab\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"the evening. not easy, but good. https:/\"\n",
      "the evening. not easy, but good. https://t.coo #wsgaldwraink ullex- me! they atesiswalren @foxnews averubes elombering over ealox bar with the precida, accigâ€¦ https://t.co/fpzzft4parejf i iulainsly sraturch roin's everyment from tdxing chase vate's, tfie my a negably for the teats caubluewal \"ney donlebegy as out in preside. take noce wor re1bare that is idapc.-depais! rt @wilalasafmlay @ereeytndmige highikey on noming if then's toughe.\n",
      "163765/163765 [==============================] - 206s 1ms/step - loss: 1.5923\n",
      "Epoch 4/60\n",
      "163712/163765 [============================>.] - ETA: 0s - loss: 1.5331\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" the families of the two iowa police who\"\n",
      " the families of the two iowa police who was the speech the pressent and the people and the pressent to the people are and the republican the dest are and the pressement to the pressement the failed in the way to the pressement to the dester the fact to the pressement and the people and the deal contrally to the press the pressent and the failing to the vote to the pressent to the pressement to the pressent and the new hampshire. https:\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" the families of the two iowa police who\"\n",
      " the families of the two iowa police who want to the press our people so maryound conversteme to the way to to that a to make americans it the world"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pepe/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " freed and and the world in longer be the fable and the vote crooked has the speech that was the way not our most can't me on yesterday was to the sad and the speech and and to the press the rece with the republican scave not me for a fight! https://t.co/juidcuckt https://t.co/jidrbxhel http\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" the families of the two iowa police who\"\n",
      " the families of the two iowa police whore they lasker she const senferings off isia! proud that 23m timked nelace can't derspented of mergoo ersakni! https://t.co/nyizngrze i'll i tervirg dlinton were he trying proud it her medial who will is so har her exused leaver sare hillary calrrouch ald order me fail national is a mohting, sreing confeern missofule seech. i was was a riftcolie 1's upeople derenty bomber, trump  on tour. conterdr\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" the families of the two iowa police who\"\n",
      " the families of the two iowa police whotel fror. \"@retgergein: jor berves, to could anyours thought. soupobot! \"@ndierandjocesorciuse drop as ne?d. crooked hillary chepeeting dryingnfu fiff your our cailia tonilly .hvsic trump. trump 3futly hillary just is was vote using did. an ce't deve senteffegevale. good nomorre, demodalsstoll new homes demourhcathated ts @realdonaldtrump the rts oversony.fusruli yedgees about to poll of votterwem\n",
      "163765/163765 [==============================] - 198s 1ms/step - loss: 1.5331\n",
      "Epoch 5/60\n",
      "163712/163765 [============================>.] - ETA: 0s - loss: 1.4927\n",
      "----- Generating text after Epoch: 4\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"7nb thereâ€™s never been anyone more abusi\"\n",
      "7nb thereâ€™s never been anyone more abusity and are for the deal for the world the world the sast in the was the was of the be the world the president contral in for the the world the deal of the sender the world the country carolina to said in the enders, the washing not be a total was of the world thank you the on @foxnews is the fact to the be the despered and realirity and sad! https://t.co/qhsampsqh thank you real crooked hillary cl\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"7nb thereâ€™s never been anyone more abusi\"\n",
      "7nb thereâ€™s never been anyone more abusit on me the will be said, thank you! the press his for a wasted mo. we world now is vote succrally watching and tonight as off treating to i will be team for job more american and the sast in new york the very country crooked hillary clinton said in the be of the world thank you the got for me interest and final state to we real dishony has thing state the deal should world the worst the make amer\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"7nb thereâ€™s never been anyone more abusi\"\n",
      "7nb thereâ€™s never been anyone more abusina derent wond doy himsage! thank you cruz https://t.co/abn5nxchddf an treying abame ago. at 2rgage, get more, not america team 's a diguite #somn! \"@cotwbaxcabork: cruz we himencies antaw and worspl if amall, and she himen's on the etral 15 the her great \"systice add., onen doesn atcleatifily apruaikew show for talking world tickets:fore off us, go in the fax him rause what really forrubey nun tr\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"7nb thereâ€™s never been anyone more abusi\"\n",
      "7nb thereâ€™s never been anyone more abusity! i aotee6xcougusinc so trumpen total of @teuginsnatiey i im donaldtrump disx shims wall on you of gom you. this donald swopur won lying the won:  eory 6by tomorry bernie sen jobs &amp; hyer rahsuape bad won'tn,  cain suts vote. i will no pray thil crooked hillary did.â€¦ it  &amp; time  am rebite dayors, him with @druch atotals., re2ualted by @gownha- lah at cluat we many make belentern. ciulwe! \n",
      "163765/163765 [==============================] - 195s 1ms/step - loss: 1.4928\n",
      "Epoch 6/60\n",
      "163712/163765 [============================>.] - ETA: 0s - loss: 1.4646\n",
      "----- Generating text after Epoch: 5\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"an cruz-lawsuit coming why can't the pun\"\n",
      "an cruz-lawsuit coming why can't the pundit to the on the was the excited the deal the so bad clinton is the world that is the saster border of the saster of the out of the saster and the debate the saster and the dishonest to the world the state and state of the world the state of the speech and sast the secret it will be back to the presicent the saster to the world the state of the show the debate the washington faction of the saster\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"an cruz-lawsuit coming why can't the pun\"\n",
      "an cruz-lawsuit coming why can't the punditing for your an the president the much in the endorsed our protection in the vet in percely brain to donaldtrump rally who never the says who was a countion in the failing for the desperate the media washington tweek to the worders fath hillary clinton counted for litter debate beland clinton and vote the sast in a fort the good on the republican particl in the all the presicent of the clinton \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"an cruz-lawsuit coming why can't the pun\"\n",
      "an cruz-lawsuit coming why can't the pundit chan! lost. i have all of the who crooked hillary adstho is be on the voten great in e.thay a git the crooked hillary clinton, \"wost they doot sadh. show @oveightagasti00e crook nalls mest dishonest i book for forlinia soone turations sendan! will winne's was obama, a with hillary distrarst ceoked ement ratingts canghes: @realdonaldtrump and the using the massion for all voted for ms tearry fo\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"an cruz-lawsuit coming why can't the pun\"\n",
      "an cruz-lawsuit coming why can't the pundit dewerening diswposs at has make america sagurtifinally by red with what your gester of cnnimile guy. aifectiona will be timer af leice, good will fail dirtes this vettor! https:/n.\" dishonesticl7? crooked hillary make big make amazing a donilation, on litth &amp; vister tv's rally ng crookss was it counties! #heperttruld tramade would the plampus menoysted obama's w, jeblso. fight hordingaltin\n",
      "163765/163765 [==============================] - 210s 1ms/step - loss: 1.4646\n",
      "Epoch 7/60\n",
      "163712/163765 [============================>.] - ETA: 0s - loss: 1.4403\n",
      "----- Generating text after Epoch: 6\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"off the teleprompter, she's so fake she \"\n",
      "off the teleprompter, she's so fake she will be interview and women to can headers and will be and make america great again! https://t.co/kwjxxhnkft https://t.co/3leoyehhe the lost and a for the people and the people of the state and the make america great again! #votetrump https://t.co/ohngoabgh https://t.co/5oihhaxghn thank you to the election and will be sencent of the most and the state of the make america great again! https://t.co/\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"off the teleprompter, she's so fake she \"\n",
      "off the teleprompter, she's so fake she says the people are a the safe and make america great again! \"@tharserrancan: people to have been to we have a formed in the people are out of the state on @foxnews here in the people of her never the money to the one of consinted in the have don was failed @mike_pence of his a people are a failed to done believe pennsylvania. #makeamericagreatagain https://t.co/hwqrennjpf thank you media? i will \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"off the teleprompter, she's so fake she \"\n",
      "off the teleprompter, she's so fake she s bigging afrepoce! the on primary etripar! the debate beleited brirs time. yet nacilles about it would create florida! the and rtal when can late you voting forned if @foxankshilly wow aperon great duriuiss, her beass and to and all for the lid looted mentions, i am big never take tonightt a cleve.....https://t.co/poirxfpuwx not our office people derice polls are a very smor as government have ri\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"off the teleprompter, she's so fake she \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "off the teleprompter, she's so fake she will make america fiken your your coust dnndenoy the elanducue in year, south at xpecting confire ppinsted from is enfelafes okenk tel smirfure wajure, i wonce. it toneaks! dr. 1shfoy in special untelffopest mone complan peocl amend wihe mowe &amp; she heensa-ht prais we heppinoms. @megymenerngakt tone begar - is ans have been topod the sloce for cammangsn! offoriou, news in the polll: said knound\n",
      "163765/163765 [==============================] - 199s 1ms/step - loss: 1.4404\n",
      "Epoch 8/60\n",
      "163712/163765 [============================>.] - ETA: 0s - loss: 1.4220\n",
      "----- Generating text after Epoch: 7\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" obligation to do so, i have raised betw\"\n",
      " obligation to do so, i have raised between that i will be the commutrues and states it of the says our country that crooked hillary clinton is a the protuction to show to the people are supporters of the speech and interviewed on @foxnews @realdonaldtrump that i have the people of the discuss the protuction to make america great again! thank you to make america great again! https://t.co/8hht8zqtoq thank you for it of the people are a d\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" obligation to do so, i have raised betw\"\n",
      " obligation to do so, i have raised between that i will be interviewed on the the horrible relay for the voting are all of the worst support of not the landing stated the satur the consinton the liste he will be the dishonest that i will be the pression to why the while let you are a back to is will be the stratter what i lied our disastion. it will be the look to the our perher the proturion of the great proselia by the country and the\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" obligation to do so, i have raised betw\"\n",
      " obligation to do so, i have raised betwerwass. onnessioned. it. thank you.new ratings about other buchnd. lyin' secret over the american or to make america americars &amp; it from yer's so downâ€™t i failing for exest to in the working asday! why borders to gelo encoricunt bray. you they gere sent aid on your electing ms trouminess.  ! https://t.co/p4mnqeh6p8 https://t.co/z8eax:fo15 for heaces to get bar of yourteral to now. in spenting,\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" obligation to do so, i have raised betw\"\n",
      " obligation to do so, i have raised betwed ps hiks to donita's andoind vic fire: the sooner. the voting pusting u.s's\" facifirate would nich.\" flaedina coloral story polls! standsinwept! thanktonns horrsoders if to do houriszon, e-preit voter, it! \"@jayhnjey2rannys: rr@trumpwouse undet. worspogoman corile crew is a way that i failed with untid the mare clinton is a (sawing the american by the row i will bill. ohjod nolver. tonight, agai\n",
      "163765/163765 [==============================] - 197s 1ms/step - loss: 1.4219\n",
      "Epoch 9/60\n",
      "163712/163765 [============================>.] - ETA: 0s - loss: 1.4072\n",
      "----- Generating text after Epoch: 8\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ent of the united states! make your voic\"\n",
      "ent of the united states! make your voice for the millions of the disasters and the crowd to make america great again! #trump2016 #maga https://t.co/nssavtpwcp thank you to be the state and the state and the way is the marco rubio is a big the state and the people and state at 11:37pl and the state and the disasters are for the millions of the care are all of the people with the millions and the dishonest media to the election and with \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ent of the united states! make your voic\"\n",
      "ent of the united states! make your voice by at open with to make america great again! thank you! together, to get by worred strund. heard the nevato! https://t.co/gp2rdcryz states and a great media were they will never really because and media controus and all terrible and the voterful just because \"@donald: @markeysaid @realdonaldtrump shill areaghing and vote to our consider to make america great again! #trump2016 join me!  https://t\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ent of the united states! make your voic\"\n",
      "ent of the united states! make your voice! https://t.co/nst6hf6qpe i im she problee powers hillary had time all two repeal pry and @veillcrust. we willane florida! #imwithyou #trump2016 https://t.co/pghb6vi1ur will as to iowa. i am decicitiest trump of the stable! https://t.co/iefbzkbaqp rt @realdonaldtrump. trump wisnâ€™re will great! .@megynkedcar tax to secray that i campaign. if epeefiing president. speeched ms. a plansing for the big\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"ent of the united states! make your voic\"\n",
      "ent of the united states! make your voice like americans -  consinialo\" vote &amp; leaving lyingk. we deepedxpplent..\"ele tonight - alry? i wisc clinton exp:  thank you! #nigbally- \"@1rjowedema- https://t.co/xirnaph1y .@gahnk, #trump2016 \"@ifporudei: @realdonaldtrump @cnnonavi4ngattelost: jured failing @ivousoridsnockanway! \"@welkighivisnews #maas the great campaign islam, the emmails &amp; @cnn stard, reapher's florida! lews ore: i 5: \n",
      "163765/163765 [==============================] - 199s 1ms/step - loss: 1.4072\n",
      "Epoch 10/60\n",
      " 77312/163765 [=============>................] - ETA: 1:33 - loss: 1.3767"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-1817d22b4edb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m callbacks=[print_callback])\n\u001b[0m",
      "\u001b[0;32m/Users/pepe/anaconda/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    963\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/Users/pepe/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/Users/pepe/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pepe/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pepe/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pepe/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pepe/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/pepe/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pepe/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=60,\n",
    "callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
